{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d172c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from paddleocr import PaddleOCR\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b6f96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /home/nonso/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3910/3910 [00:41<00:00, 94.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /home/nonso/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:56<00:00, 175.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /home/nonso/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2138/2138 [00:25<00:00, 83.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/11 22:56:44] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/nonso/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/nonso/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/nonso/ai-multimodal-learning-project/venv/lib/python3.12/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/nonso/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize PaddleOCR once (supports French, English, etc.)\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')  # Use 'fr' for French if needed\n",
    "\n",
    "def extract_text_from_html(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            soup = BeautifulSoup(f, \"lxml\")\n",
    "        text = soup.get_text(separator=\" \", strip=True)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BeautifulSoup failed for {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_with_docling_or_ocr(file_path):\n",
    "    # Handle HTML separately with BeautifulSoup\n",
    "    if file_path.lower().endswith(('.html', '.htm')):\n",
    "        return extract_text_from_html(file_path)\n",
    "\n",
    "    # Try Docling\n",
    "    try:\n",
    "        converter = DocumentConverter()\n",
    "        doc = converter.convert(file_path)\n",
    "        if hasattr(doc, 'text'):\n",
    "            text = doc.text\n",
    "            if text.strip():\n",
    "                return text\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Docling failed for {file_path}: {e}\")\n",
    "\n",
    "    # Fallback to PaddleOCR for images\n",
    "    if file_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        print(f\"ðŸ” Falling back to PaddleOCR for {file_path}\")\n",
    "        try:\n",
    "            result = ocr.ocr(file_path, cls=True)\n",
    "            extracted_text = \"\"\n",
    "            for line in result:\n",
    "                for box in line:\n",
    "                    extracted_text += box[1][0] + \"\\n\"\n",
    "            return extracted_text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PaddleOCR also failed for {file_path}: {e}\")\n",
    "\n",
    "    return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e383b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents_to_text(root_dir):\n",
    "    rows = []\n",
    "\n",
    "    for folder_name in os.listdir(root_dir):\n",
    "        label = folder_name\n",
    "        folder_path = os.path.join(root_dir, folder_name)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            if file_path.lower().endswith(('.html', '.htm', '.jpg', '.jpeg', '.png')):\n",
    "                text = extract_text_with_docling_or_ocr(file_path)\n",
    "                if text:\n",
    "                    rows.append({\n",
    "                        \"text\": text,\n",
    "                        \"label\": label\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = process_documents_to_text(\"/home/nonso/ai-multimodal-learning-project/Finance-Ai-Project/data/processed/sujet_images_by_class\")\n",
    "\n",
    "df.to_csv(\"finance_text_dataset.csv\", index=False)\n",
    "print(\"âœ… Dataset saved with\", len(df), \"entries.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function posix.listdir(path=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b970643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
